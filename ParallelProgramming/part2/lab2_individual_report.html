<!DOCTYPE html>
<!-- saved from url=(0073)file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <title>lab2_individual_report</title>
      
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:///C:/Users/AW/.vscode/extensions/shd101wyy.markdown-preview-enhanced-0.3.13/node_modules/@shd101wyy/mume/dependencies/katex/katex.min.css">
      
      
      
      
      
      
      
      
      

      <style> 
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
 
      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview   ">
      <h1>CS3211 Part2 Individual Report</h1>
<ul>
<li>(c) 2019 Wang Huaqiang</li>
</ul>
<hr>
<ul>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#1-lab1-openmp-and-memory-behaviour">1. Lab1: openMP, and memory behaviour</a>
<ul>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#11-task-1">1.1. Task 1</a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#12-task-2">1.2. Task 2</a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#13-task-3">1.3. Task 3</a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#14-task-4">1.4. Task 4</a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#15-task-5">1.5. Task 5</a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#16-task-6">1.6. Task 6</a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#17-task-7">1.7. Task 7</a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#18-task-8">1.8. Task 8</a></li>
</ul>
</li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#2-lab2-accuracy">2. Lab2 Accuracy</a>
<ul>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#21-accuracy-examples">2.1. Accuracy examples</a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#22-gmp-library">2.2. GMP library</a></li>
</ul>
</li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#3-lab3-more-on-accuracy">3. Lab3 More on accuracy</a>
<ul>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#31-task1">3.1. Task1</a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#32-task2">3.2. Task2</a></li>
</ul>
</li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#4-lab4-automata">4. Lab4 Automata</a>
<ul>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#41-simple-automata">4.1. Simple automata</a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#42-construct-automata">4.2. Construct automata</a>
<ul>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#421-abba">4.2.1. <code>.*abba</code></a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#422-aabbbaa">4.2.2. <code>.*a*b*b*a</code></a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#423-ababca">4.2.3. <code>(aba)|(bca)</code></a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#424-summary">4.2.4. summary</a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#425-problems-that-automata-processors-are-naturally-suited-for">4.2.5. problems that automata processors are naturally suited for</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#5-appendix">5. Appendix</a>
<ul>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#51-lab01-on-server-run-result">5.1. Lab01 on server run result</a></li>
<li><a href="file:///C:/Users/AW/AppData/Local/Temp/mume201935-14300-1q8brde.w2ha.html#52-unum-program">5.2. UNUM program</a></li>
</ul>
</li>
</ul>
<hr>
<h1 class="mume-header" id="1-lab1-openmp-and-memory-behaviour">1. Lab1: openMP, and memory behaviour</h1>

<h2 class="mume-header" id="11-task-1">1.1. Task 1</h2>

<blockquote>
<p>Compile and run the matrix multiplication program. Observe the number of threads that the program is using. What is the number? Why is it this number? You can change the number of threads using the function omp_set_num_threads(int) in your OpenMP code, or the environment variable OMP_NUM_THREADS.</p>
</blockquote>
<p>8 threads.</p>
<p>Because this time I was running it on my computer, and my computer has a Intel-I76700HQ CPU, which has 4 cores and 8 threads. Therefore openMP used all useable threads tio get the best speed.</p>
<h2 class="mume-header" id="12-task-2">1.2. Task 2</h2>

<blockquote>
<p>Tabulate the (unloaded) runtime for the program working on arrays of size 128 up to 2048, and for threads from 1 to (say) 32. The size of the problem should go across the table, and one row for each number of threads (1,2,4,8,16,32). Note that the times will vary dramatically, dependant on other events in the particular computer you are using. In your table, should you use the minimum, average or maximum value for the times?</p>
</blockquote>
<table>
<thead>
<tr>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
</tr>
</thead>
<tbody>
<tr>
<td>128</td>
<td>0.0141</td>
<td>0.0103</td>
<td>0.0047</td>
<td>0.0033</td>
<td>0.005</td>
<td>0.0042</td>
<td>0.0039</td>
<td>0.0127</td>
</tr>
<tr>
<td>256</td>
<td>0.127</td>
<td>0.0693</td>
<td>0.0587</td>
<td>0.0419</td>
<td>0.0376</td>
<td>0.0485</td>
<td>0.0354</td>
<td>0.0333</td>
</tr>
<tr>
<td>512</td>
<td>1.2444</td>
<td>0.6714</td>
<td>0.4496</td>
<td>0.4216</td>
<td>0.3465</td>
<td>0.3271</td>
<td>0.3048</td>
<td>0.2839</td>
</tr>
<tr>
<td>1024</td>
<td>11.4018</td>
<td>5.611</td>
<td>4.2239</td>
<td>3.6943</td>
<td>3.5334</td>
<td>3.3828</td>
<td>3.229</td>
<td>3.1684</td>
</tr>
</tbody>
</table>
<p>Notes: After 8 threads, the time of exec will not change at all, for the computer I used support up to 8 threads in parallel.</p>
<p>Because we have other programs running on the machine, we run the test script multiple times. And then, we pick the shortest time in result, for these results are closest to the ideal performance of the program being tested.</p>
<h2 class="mume-header" id="13-task-3">1.3. Task 3</h2>

<blockquote>
<p>Record and interpret your table. What do the rows and columns tell you? Can you relate any discontinuities in the results tabulated to things you might know or discover about the processor?</p>
</blockquote>
<p><img src="file:///F:/workpath/Notes/ParallelProgramming/part2/doc/origin_data.png" alt="origin_data.png"><br>
<img src="file:///F:/workpath/Notes/ParallelProgramming/part2/doc/origin_data2.png" alt="origin_data2.png"><br>
<img src="file:///F:/workpath/Notes/ParallelProgramming/part2/doc/time_in_total.png" alt="time_in_total.png"></p>
<p>main point:</p>
<ul>
<li>for the same workload: the curve is almost a hyperbola when there is still thread available</li>
<li>for different work loads: the more workload, the more time (in total: use complexity analyze)</li>
</ul>
<p>The complexity of the matrix multi program is:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><msup><mi>n</mi><mn>3</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n^3)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>s.t. n is the size of the array.</p>
<p>Then form this formula:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>P</mi><mi>e</mi><mi>r</mi><mi>U</mi><mi>n</mi><mi>i</mi><mi>t</mi><mo>=</mo><mfrac><mrow><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mo>∗</mo><mi>T</mi><mi>h</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>N</mi><mi>u</mi><mi>m</mi></mrow><mrow><mi>s</mi><mi>i</mi><mi>z</mi><msup><mi>e</mi><mn>3</mn></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">TimePerUnit=\frac{time*ThreadNum}{size^3}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault">i</span><span class="mord mathdefault">m</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mord mathdefault">n</span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.05744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="mord mathdefault">i</span><span class="mord mathdefault">m</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault">h</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">u</span><span class="mord mathdefault">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>We got the following graph.</p>
<p><img src="file:///F:/workpath/Notes/ParallelProgramming/part2/doc/time_per_unit.png" alt="time_per_unit.png"></p>
<p>This graph is the most important one in the three graphs in this section. We can see from this graph that time cost for per unit workload keeps going higher and higher when the number of parallel thread grows. It is easy to explain as the speed of different thread may be different, and the processor will have to spend more time on thread communication, joining, etc. . an interesting result is for 128-matrix. When using 8 threads for a 128kb matrix, time cost for per unit workload goes up abnormally when there is 8 thread. It is probably because of the problem that for a 128-matrix, the cost of controlling 8 threads and merging the result of 8 threads has overpowered the cost of actually calculate.</p>
<h2 class="mume-header" id="14-task-4">1.4. Task 4</h2>

<blockquote>
<p>Repeat your experiment from Tasks 1..3, only this time use threads from 1 to 40. Compile and run the program as before, tabulating the results. In your writeup, you should be able to explain why we are interested in up to 8 threads on the lab machines and 40 threads on the tembusu machines, and also explain the tabulated results in terms of speedup.</p>
</blockquote>
<p>For full result table, see <code>Appendix</code>.</p>
<p>For the cluster support more than 8 threads, so the time will be further shortened when there are more than 8 threads available. The results we can get from the graphs as almost the same as Task3.</p>
<p><img src="file:///F:/workpath/Notes/ParallelProgramming/part2/doc/cluster_origin_data.png" alt="cluster_origin_data.png"><br>
<img src="file:///F:/workpath/Notes/ParallelProgramming/part2/doc/cluster_time_in_total.png" alt="cluster_time_in_total.png"><br>
<img src="file:///F:/workpath/Notes/ParallelProgramming/part2/doc/cluster_time_per_unit.png" alt="cluster_time_per_unit.png"></p>
<p>The same as the result on PC: the result for matrix size 256 and 128 are not stable, is is because of the fact the data size is too small for too many parallel threads. Also, we can learn from the graph that the 256-size matrix can make use of more threads than 128-size matrix.</p>
<p>What is interesting is, though the cluster support up to 40 threads, the timing result for this program hardly changes after 30-32 threads. It may because of 1) the difference is just not significant or 2) the cluster do not support so many threads.</p>
<h2 class="mume-header" id="15-task-5">1.5. Task 5</h2>

<blockquote>
<p>Download, compile and run the program testmem.c:</p>
</blockquote>
<pre data-role="codeBlock" data-info="" class="language-"><code>e0389042@xcnd0:~$ ./testmem 
Array size: 4 kB and time taken is 0.177750 secs
Array size: 8 kB and time taken is 0.177532 secs
Array size: 16 kB and time taken is 0.177656 secs
Array size: 32 kB and time taken is 0.178022 secs
Array size: 64 kB and time taken is 0.195783 secs
Array size: 128 kB and time taken is 0.196086 secs
Array size: 256 kB and time taken is 0.222868 secs
Array size: 512 kB and time taken is 0.258163 secs
Array size: 1024 kB and time taken is 0.261301 secs
Array size: 2048 kB and time taken is 0.262450 secs
Array size: 4096 kB and time taken is 0.261389 secs
Array size: 8192 kB and time taken is 0.261941 secs
Array size: 16384 kB and time taken is 0.406156 secs
Array size: 32768 kB and time taken is 0.549750 secs
Array size: 65536 kB and time taken is 0.553372 secs

</code></pre><h2 class="mume-header" id="16-task-6">1.6. Task 6</h2>

<blockquote>
<p>Tabulate and explain the results you got in task 5. You could even plot them</p>
</blockquote>
<table>
<thead>
<tr>
<th>array size(kb)</th>
<th>array size (2 exp kb)</th>
<th>time</th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>2</td>
<td>0.177851</td>
</tr>
<tr>
<td>8</td>
<td>3</td>
<td>0.177634</td>
</tr>
<tr>
<td>16</td>
<td>4</td>
<td>0.177675</td>
</tr>
<tr>
<td>32</td>
<td>5</td>
<td>0.178166</td>
</tr>
<tr>
<td>64</td>
<td>6</td>
<td>0.195574</td>
</tr>
<tr>
<td>128</td>
<td>7</td>
<td>0.196206</td>
</tr>
<tr>
<td>256</td>
<td>8</td>
<td>0.228457</td>
</tr>
<tr>
<td>512</td>
<td>9</td>
<td>0.257428</td>
</tr>
<tr>
<td>1024</td>
<td>10</td>
<td>0.261333</td>
</tr>
<tr>
<td>2048</td>
<td>11</td>
<td>0.262480</td>
</tr>
<tr>
<td>4096</td>
<td>12</td>
<td>0.261404</td>
</tr>
<tr>
<td>8192</td>
<td>13</td>
<td>0.261840</td>
</tr>
<tr>
<td>16384</td>
<td>14</td>
<td>0.407127</td>
</tr>
<tr>
<td>32768</td>
<td>15</td>
<td>0.552639</td>
</tr>
<tr>
<td>65536</td>
<td>16</td>
<td>0.554280</td>
</tr>
</tbody>
</table>
<p><img src="file:///F:/workpath/Notes/ParallelProgramming/part2/doc/storage_level.png" alt="storage_level.png"></p>
<p>This is because of the cache of CPU. For such program that need much data, load data from cache/memory is the main cost of time. From the data above, we can make a roughly guess about the cache size of that platform, for at some point the time changes suddenly:</p>
<table>
<thead>
<tr>
<th>cache</th>
<th>size</th>
</tr>
</thead>
<tbody>
<tr>
<td>L1</td>
<td>32kb</td>
</tr>
<tr>
<td>L2</td>
<td>256kb</td>
</tr>
<tr>
<td>L3</td>
<td>8192kb</td>
</tr>
<tr>
<td>memory</td>
<td>...</td>
</tr>
</tbody>
</table>
<p>Above is only a roughly estimate. The real cache size and <em>cache level</em> may be quite different from that.</p>
<h2 class="mume-header" id="17-task-7">1.7. Task 7</h2>

<blockquote>
<p>Use perf stat to produce a summary of program performance:</p>
</blockquote>
<p>Unfortunately, we do not have the permission to use perf on the cluster, and perf does not support Windows Subsystem of Linux. The following test was based on a VM, and as a sequence the result could be different from running perf on a normal linux.</p>
<p>Update: perf is able to work correctly on lab computer. The data below is tested on PC in lab.</p>
<h2 class="mume-header" id="18-task-8">1.8. Task 8</h2>

<blockquote>
<p>Use perf to measure (L1 and L3) cache loads and misses for different sizes of array. Tabulate and interpret the results.</p>
</blockquote>
<table>
<thead>
<tr>
<th>array size(kb)</th>
<th>L1d load</th>
<th>L1d miss</th>
<th>L1i miss</th>
<th>cache miss</th>
<th>cache reference</th>
</tr>
</thead>
<tbody>
<tr>
<td>4</td>
<td>405,746,474</td>
<td>21,576</td>
<td>54,847</td>
<td>31,509</td>
<td>85,767</td>
</tr>
<tr>
<td>8</td>
<td>402,664,671</td>
<td>14,928</td>
<td>42,710</td>
<td>23,994</td>
<td>79,681</td>
</tr>
<tr>
<td>16</td>
<td>405,687,255</td>
<td>178,288</td>
<td>35,386</td>
<td>30,194</td>
<td>141,430</td>
</tr>
<tr>
<td>32</td>
<td>403,003,206</td>
<td>1,185,088</td>
<td>64,122</td>
<td>26,809</td>
<td>161,015</td>
</tr>
<tr>
<td>64</td>
<td>403,395,399</td>
<td>67,661,705</td>
<td>50,310</td>
<td>37,814</td>
<td>154,295</td>
</tr>
<tr>
<td>128</td>
<td>404,492,124</td>
<td>67,155,288</td>
<td>48,122</td>
<td>38,344</td>
<td>792,055</td>
</tr>
<tr>
<td>256</td>
<td>402,956,914</td>
<td>66,853,531</td>
<td>43,392</td>
<td>36,797</td>
<td>69,822,383</td>
</tr>
<tr>
<td>512</td>
<td>404,075,270</td>
<td>67,148,640</td>
<td>49,578</td>
<td>27,597</td>
<td>122,057,291</td>
</tr>
<tr>
<td>1024</td>
<td>405,196,380</td>
<td>66,977,566</td>
<td>45,674</td>
<td>41,647</td>
<td>132,987,320</td>
</tr>
<tr>
<td>2048</td>
<td>407,500,623</td>
<td>66,777,332</td>
<td>51,388</td>
<td>69,222</td>
<td>133,590,015</td>
</tr>
<tr>
<td>4096</td>
<td>411,726,363</td>
<td>66,408,510</td>
<td>57,559</td>
<td>384,611</td>
<td>130,047,320</td>
</tr>
<tr>
<td>8192</td>
<td>408,327,091</td>
<td>66,815,889</td>
<td>64,269</td>
<td>15,271,015</td>
<td>130,400,717</td>
</tr>
<tr>
<td>16384</td>
<td>409,444,839</td>
<td>67,824,857</td>
<td>73,831</td>
<td>47,592,262</td>
<td>119,528,173</td>
</tr>
<tr>
<td>32768</td>
<td>412,063,179</td>
<td>67,732,654</td>
<td>65,126</td>
<td>61,635,793</td>
<td>113,824,704</td>
</tr>
<tr>
<td>65536</td>
<td>421,580,375</td>
<td>67,927,086</td>
<td>120,984</td>
<td>68,718,136</td>
<td>111,266,562</td>
</tr>
<tr>
<td>131072</td>
<td>438,044,280</td>
<td>67,623,431</td>
<td>269,110</td>
<td>72,152,173</td>
<td>110,704,566</td>
</tr>
<tr>
<td>262144</td>
<td>471,126,403</td>
<td>68,676,788</td>
<td>774,682</td>
<td>71,893,236</td>
<td>109,007,143</td>
</tr>
</tbody>
</table>
<p>From the table above we can learn that from 8kb, l1 miss start to rise. After 256kb, the total reference of L3 cache goes up. And after 4096kb, cache miss begin to rise greatly. Theses are critical points that L1 cache is fully used, L2 cache (or something like that) is fully used, and the processor has run out of its on-chip L3 cache.</p>
<hr>
<h1 class="mume-header" id="2-lab2-accuracy">2. Lab2 Accuracy</h1>

<h2 class="mume-header" id="21-accuracy-examples">2.1. Accuracy examples</h2>

<blockquote>
<p>This one fails with an interesting effect. What is the interesting 2x value in this case? Make sure you understand exactly what effect is happening here.</p>
</blockquote>
<p>Important part of result is:</p>
<pre data-role="codeBlock" data-info="" class="language-"><code>Adding 2000000000 1s to 0 gives this result: 2000000000
Adding 2100000000 1s to 0 gives this result: 2100000000
Overflow happened at 2147483648.
Adding 2200000000 1s to 0 gives this result: -2094967296
Adding 2300000000 1s to 0 gives this result: -1994967296
Adding 2400000000 1s to 0 gives this result: -1894967296
</code></pre><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2147483648</mn><mo>=</mo><msup><mn>2</mn><mo>(</mo></msup><mn>31</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">2147483648=2^(31)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">1</span><span class="mord">4</span><span class="mord">7</span><span class="mord">4</span><span class="mord">8</span><span class="mord">3</span><span class="mord">6</span><span class="mord">4</span><span class="mord">8</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mopen mtight">(</span></span></span></span></span></span></span></span><span class="mord">3</span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span></p>
<p>What has happened is, <code>int</code> in C (in test environment) is saved in 32-bit format. The 31st(highest) bit is sign bit, and from 30th to 0th bit are number bits. When 1 is added to <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>2</mn><mo>(</mo></msup><mn>31</mn><mo>)</mo><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2^(31)-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.138em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mopen mtight">(</span></span></span></span></span></span></span></span><span class="mord">3</span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>, a one was carried on to the 31th bit. The 31th bit become 1 rather than 0, which caused overflow. The next number is -2147483648.</p>
<blockquote>
<p>Compile and run the fpadd1 program. Observe the accuracy of the answers you get. Examine the code. Examine the output. You will see a peculiarity between 16500000 and 17000000 additions. Note that you would really expect 19000000 1s added together to have the value 19000000, but it is way way out!</p>
</blockquote>
<pre data-role="codeBlock" data-info="" class="language-"><code>Adding 16000000 1s to 0 gives this result: 16000000.0
Adding 16500000 1s to 0 gives this result: 16500000.0
Adding 17000000 1s to 0 gives this result: 16777216.0
Adding 17500000 1s to 0 gives this result: 16777216.0
</code></pre><p>As we can see from above, the number did not increase from 16777216.0. What has happened is related to the mechanism of float add. To do a float add, the ALU in processor must align the exp bits and num bits in IEEE-754 float. When add 1 to 16777216.0, ALU have to right shift (&gt;&gt;) the num bits and left shift (&lt;&lt;) the exp bits. The problem is, the exp bit of 1 is a far cry from 16777216.0, so the num bit right shifted too many bits for align. As a result, the num bit become zero, and the result of add is always 16777216.0.</p>
<blockquote>
<p>Compile and run the fpadd2 program. Observe the accuracy of the answers you get. Examine the code. Examine the output. You will see peculiarities between 1000000 and 1500000, 4000000 and 4500000 additions. Your goal here is to make sure you understand why this mindlessly simple program acts the way it does.</p>
</blockquote>
<pre data-role="codeBlock" data-info="" class="language-"><code>Adding 1 to 0.3, lots of times...
Adding 500000 1s to 0.3 gives this result:   500000.3
Adding 1000000 1s to 0.3 gives this result:  1000000.3
Adding 1500000 1s to 0.3 gives this result:  1500000.2
Adding 2000000 1s to 0.3 gives this result:  2000000.2
Adding 2500000 1s to 0.3 gives this result:  2500000.2
Adding 3000000 1s to 0.3 gives this result:  3000000.2
Adding 3500000 1s to 0.3 gives this result:  3500000.2
Adding 4000000 1s to 0.3 gives this result:  4000000.2
Adding 4500000 1s to 0.3 gives this result:  4500000.0
Adding 5000000 1s to 0.3 gives this result:  5000000.0
Adding 5500000 1s to 0.3 gives this result:  5500000.0
</code></pre><p>The reason of the above result is not as obvious as the one above. To make it clear, some important float values are listed below.</p>
<table>
<thead>
<tr>
<th>Number</th>
<th>Value actually in float</th>
<th>conversion error</th>
<th>Binary Representation</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.3</td>
<td>0.30000001192...</td>
<td>1.2E-8</td>
<td>0 01111101 00110011001100110011010</td>
</tr>
<tr>
<td>1000000.3</td>
<td>1000000.3125</td>
<td>0.0125</td>
<td>0 10010010 11101000010010000000101</td>
</tr>
<tr>
<td>1500000.2</td>
<td>1500000.25</td>
<td>0.05</td>
<td>0 10010011 01101110001101100000010</td>
</tr>
<tr>
<td>1500000.3</td>
<td>1500000.25</td>
<td>-0.05</td>
<td>0 10010011 01101110001101100000010</td>
</tr>
<tr>
<td>4000000.3</td>
<td>4000000.25</td>
<td>-0.05</td>
<td>0 10010100 11101000010010000000001</td>
</tr>
<tr>
<td>10000000.3</td>
<td>10000000</td>
<td>-0.3</td>
<td>0 10010110 00110001001011010000000</td>
</tr>
</tbody>
</table>
<p>ref: <a href="https://www.h-schmidt.net/FloatConverter/IEEE754.html">https://www.h-schmidt.net/FloatConverter/IEEE754.html</a></p>
<p>Then the answer is obvious. The main reason is, as the float number grows larger and larger, its accuracy gets worse and worse. For the exp bits is getting larger and larger, the internal between two exact floats is also getting larger and larger. As we can see from the represent of <code>1500000.2</code> and <code>1500000.3</code>, at that time the <code>float</code> is not precise enough to distinguish them.</p>
<p>The second reason is, IEEE-754 float is not exact. It also lead to the result that +1 is not always exact.</p>
<blockquote>
<p>Compile and run the fporder program. Run it multiple times - each time it will choose a different set of values to add. Observe the accuracy of the answers you get. Examine the code. Examine the output. Your goal here is to make sure you understand why this mindlessly simple program acts the way it does.</p>
</blockquote>
<pre data-role="codeBlock" data-info="" class="language-"><code>Adding 20 (pseudo)randomly generated floating point numbers for 1 to 20 and 20 down to 1
Sum from 1 to 20 is 681.691467
Sum from 20 to 1 is 681.691589
</code></pre><p>As we mentioned above, the ieee-754 float numbers are not precise, and when they are being calculated, there will be precision lose from exp-align. In the instance above, <code>add</code> operations are in different sequence. The diverge of result starts from the beginning of the add sequence.</p>
<blockquote>
<p>Compile and run the fpomp program. Run it multiple times - each time it will choose a different set of values to add. Observe the accuracy of the answers you get. Examine the code. Examine the output. Try running the program on tembusu (use nodes between xcna0 and xcna15 - they have been reserved for CS3211). Your goal here is to make sure you understand why this mindlessly simple program acts the way it does. The tasks exhibit some of the issues with the use of floating point numbers, and you should develop a clear understanding of the underlying reasons for these issues.</p>
</blockquote>
<pre data-role="codeBlock" data-info="" class="language-"><code>Adding 100000 randomly generated floating point numbers using 8 threads

Final sum is 3068417.750000
Final sum is 3068418.000000
Final sum is 3068418.000000
Final sum is 3068417.750000
Final sum is 3068418.000000
....
</code></pre><p>The reason is almost the same. But in this case, for each thread, add operations have a sequence, it will not influence the result of this thread. The different in results comes from the sequence of thread joining: the threads finish their work in random sequence, so their results will be joined in random sequence. As mentioned above, the sequence of float op will influence the final result. So that is the reason.</p>
<h2 class="mume-header" id="22-gmp-library">2.2. GMP library</h2>

<blockquote>
<p>Write a new version of the integer program intadd1.c, gmpadd1.c, that makes use of the GMP library. What is the interesting 2 x value in this case? Approximately how many decimal digits might this be?</p>
</blockquote>
<p>For source code, see <code>Appendix</code>.</p>
<p>We did not find that 2x in GMP library.</p>
<p>TBD</p>
<hr>
<h1 class="mume-header" id="3-lab3-more-on-accuracy">3. Lab3 More on accuracy</h1>

<h2 class="mume-header" id="31-task1">3.1. Task1</h2>

<blockquote>
<p>Task 1: Try running the program with various graduations, and see if you can find a different value. Try using a bigger (64-bit) float. Can you get a better minimum than 2.0? What if &gt; the large integer was 10,000,000,000,000 instead of 10,000,000? I managed to get this, by using floats, and a range very near to 1.3:</p>
</blockquote>
<p>One instance is:</p>
<pre data-role="codeBlock" data-info="" class="language-"><code>(double)
Large int: 10000000.000000
Trying 10000 slices between 1.299999 and 1.300001
Minimum value is  -366803.0, range 1.0 to        1.3
</code></pre><p>It also come from the problem that when <code>abs(x)</code> is too large, <code>ieee-754-float(x)</code> will become less precise.</p>
<h2 class="mume-header" id="32-task2">3.2. Task2</h2>

<blockquote>
<p>Task 2: Construct a version of fpminval.c called unumminval.c. Your version could try computing bounds, doing perhaps [1,1.2] [1.2,1.4] [1.4,1.6] [1.6,1.8] and [1.8,2.0]. What is the minimum value of the function in this range?</p>
</blockquote>
<p>For source code, see <code>Appendix</code>.</p>
<p>The results are:</p>
<pre data-role="codeBlock" data-info="" class="language-"><code>   Result of [1,1.20001220703125) is [0,0.440032958984375)
   Result of (1.1999969482421875,1.4000091552734375) is (4.43994140625,4.9600830078125)
   Result of (1.399993896484375,1.600006103515625) is (2.9599609375,3.560028076171875)
   Result of (1.5999908447265625,1.8000030517578125) is (3.559967041015625,4.24005126953125)
   Result of (1.79998779296875,2] is (4.23992919921875,5]

</code></pre><hr>
<h1 class="mume-header" id="4-lab4-automata">4. Lab4 Automata</h1>

<h2 class="mume-header" id="41-simple-automata">4.1. Simple automata</h2>

<p>We represent these NFAs in the form of regular expressions, as they are equivalent mathematically. The two NFAs in 1.2 can be represented as:</p>
<pre data-role="codeBlock" data-info="re" class="language-re"><code>[^a]*(a[^a]*a[^a]*)*a
</code></pre><p>and</p>
<pre data-role="codeBlock" data-info="re" class="language-re"><code>.*a.*b
</code></pre><h2 class="mume-header" id="42-construct-automata">4.2. Construct automata</h2>

<h3 class="mume-header" id="421-abba">4.2.1. <code>.*abba</code></h3>

<blockquote>
<p>Construct an NFA which signals every time there is an “abba” sequence found in a string.</p>
</blockquote>
<p><img src="file:///F:/workpath/Notes/ParallelProgramming/part2/doc/am1.png" alt="am1.png"></p>
<h3 class="mume-header" id="422-aabbbaa">4.2.2. <code>.*a[^a]*b[^b]*b[^a]*a</code></h3>

<blockquote>
<p>Construct an NFA which matches whenever <code>a*b*b*a</code> is found. The <code>*</code> characters indicatethere can be other characters between the “a”s and “b”s. Note though that “abbba” would not match (there should be only one of each character).</p>
</blockquote>
<p><img src="file:///F:/workpath/Notes/ParallelProgramming/part2/doc/am2.png" alt="am2.png"></p>
<h3 class="mume-header" id="423-ababca">4.2.3. <code>(aba)|(bca)</code></h3>

<blockquote>
<p>Construct a recognizer for instances of either of the two sequences “aba” and “bca”. Do this both as a single NFA, and as two NFAs (with two distinct starting states).</p>
</blockquote>
<p><img src="file:///F:/workpath/Notes/ParallelProgramming/part2/doc/am3.png" alt="am3.png"></p>
<h3 class="mume-header" id="424-summary">4.2.4. summary</h3>

<blockquote>
<p>Assuming the degree of parallelism is expressed as a percentage of the program automata cells that are active, what is the maximum degree of parallelism you see with each of the automata you have constructed today?</p>
</blockquote>
<table>
<thead>
<tr>
<th>NFA</th>
<th>maximum degree of parallelism</th>
<th>Instance</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0.6</td>
<td>abba</td>
</tr>
<tr>
<td>2</td>
<td>0.6</td>
<td>abba</td>
</tr>
<tr>
<td>3 single NFA</td>
<td>0.43</td>
<td>aba</td>
</tr>
<tr>
<td>3 double NFA</td>
<td>0.375</td>
<td>aba</td>
</tr>
</tbody>
</table>
<h3 class="mume-header" id="425-problems-that-automata-processors-are-naturally-suited-for">4.2.5. problems that automata processors are naturally suited for</h3>

<blockquote>
<p>Can you characterize the sort of problems that automata processors are naturally suited for?</p>
</blockquote>
<p>We assume automata mentioned here are DFAs/NFAs, not more powerful calculate model such as PDAs (push down automata). Then, as DFAs/NFAs are equivalent with REGs (regular expressions), they are naturally suitable for regular expressions match. NFA model makes it possible to match REGs in parallel.</p>
<hr>
<h1 class="mume-header" id="5-appendix">5. Appendix</h1>

<h2 class="mume-header" id="51-lab01-on-server-run-result">5.1. Lab01 on server run result</h2>

<pre data-role="codeBlock" data-info="" class="language-"><code>0	128	256	512	1024	2048
1	0.0321	0.2055	1.7772	16.8814	197.7487
2	0.0165	0.1353	1.2492	9.2177	98.8609
3	0.0127	0.0998	0.6598	6.6496	68.5613
4	0.0092	0.0753	0.5501	6.0979	53.7998
5	0.0081	0.0605	0.5198	4.3528	45.4109
6	0.0066	0.0517	0.4284	3.7857	38.7627
7	0.0056	0.0442	0.3675	3.45	34.005
8	0.0047	0.0432	0.3218	3.1182	30.3822
9	0.0059	0.0506	0.3032	2.9571	27.8586
10	0.0124	0.0395	0.2661	2.5641	24.9746
11	0.0095	0.0401	0.2629	2.516	23.5508
12	0.012	0.0377	0.2949	2.48	22.9834
13	0.0089	0.0405	0.2771	2.307	21.1612
14	0.0084	0.0357	0.2748	2.422	21.1078
15	0.0085	0.0369	0.2723	2.2265	20.084
16	0.008	0.0381	0.2777	2.1247	20.7971
17	0.0108	0.0334	0.244	2.1415	19.4741
18	0.0103	0.0356	0.2572	2.1092	19.7547
19	0.0106	0.0318	0.2648	2.0262	18.9515
20	0.0078	0.0376	0.2394	2.0437	18.0223
21	0.0123	0.0343	0.2332	2.0632	18.0321
22	0.0108	0.0324	0.2477	2.0955	18.0249
23	0.0132	0.0296	0.2434	1.9846	17.3269
24	0.0153	0.0344	0.2183	1.8939	16.9453
25	0.0071	0.0448	0.2502	1.9459	17.131
26	0.006	0.037	0.2307	2.0052	17.1392
27	0.0079	0.0308	0.2374	1.8352	16.4942
28	0.0071	0.0344	0.228	1.8935	16.8509
29	0.0079	0.0355	0.2605	1.9344	16.1381
30	0.006	0.0368	0.2454	1.8438	16.0949
31	0.008	0.0359	0.2292	1.9044	15.9518
32	0.0066	0.0372	0.2143	1.8301	15.8855
33	0.0064	0.0363	0.2359	1.873	15.6439
34	0.0061	0.0349	0.2324	1.7436	15.5178
35	0.0054	0.0373	0.2222	1.8269	15.3561
36	0.0064	0.039	0.2316	1.7805	15.5643
37	0.0066	0.0443	0.2304	1.7568	15.6579
38	0.0065	0.0414	0.2325	1.7576	15.6159
39	0.0062	0.0406	0.2216	1.7738	15.1794
40	0.0061	0.0384	0.2294	1.7768	15.3292
</code></pre><h2 class="mume-header" id="52-unum-program">5.2. UNUM program</h2>

<pre data-role="codeBlock" data-info="c" class="language-c"><span class="token comment">/* NUS - CS3211 AY2017/2018 Sem 2
 *
 * (c) 2019 Huaqiang Wang
 *
 */</span>

<span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;stdio.h&gt;</span></span>
<span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;stdlib.h&gt;</span></span>
<span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;unum.h&gt;</span></span>
<span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;string.h&gt;</span></span>

<span class="token macro property">#<span class="token directive keyword">define</span> PROG "unumcalc"</span>


<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span><span class="token operator">*</span>argv<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token function">unum_set_env</span><span class="token punctuation">(</span> <span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span> <span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token macro property">#<span class="token directive keyword">define</span> UBND_ROP(result,op1,oper,op2)   \
  ubnd_set_str(u1, op1); \
  ubnd_set_str(u2, op2); \
  ubnd_#oper(result,u1, u2);</span>

  <span class="token macro property">#<span class="token directive keyword">define</span> VAR(name, val) UBND_VAR(#name); ubnd_set_str(#name,#val)</span>

  <span class="token function">UBND_VAR</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">ubnd_set_str</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token string">"[1.8,2.0]"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">UBND_VAR</span><span class="token punctuation">(</span>one<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">ubnd_set_str</span><span class="token punctuation">(</span>one<span class="token punctuation">,</span><span class="token string">"1.0"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">UBND_VAR</span><span class="token punctuation">(</span>n_one<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">ubnd_set_str</span><span class="token punctuation">(</span>n_one<span class="token punctuation">,</span><span class="token string">"-1.0"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">UBND_VAR</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">UBND_VAR</span><span class="token punctuation">(</span>temp<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token comment">//VAR(bigint, "10000000.0");</span>
  <span class="token function">UBND_VAR</span><span class="token punctuation">(</span>bigint<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">ubnd_set_str</span><span class="token punctuation">(</span>bigint<span class="token punctuation">,</span><span class="token string">"10000000.0"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token comment">//VAR(opt, "1.3");</span>
  <span class="token function">UBND_VAR</span><span class="token punctuation">(</span>opt<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">ubnd_set_str</span><span class="token punctuation">(</span>opt<span class="token punctuation">,</span><span class="token string">"1.3"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token comment">//VAR(three, "3.0");</span>
  <span class="token function">UBND_VAR</span><span class="token punctuation">(</span>three<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">ubnd_set_str</span><span class="token punctuation">(</span>three<span class="token punctuation">,</span><span class="token string">"3.0"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">//float f(float x) {</span>
<span class="token comment">//  return -1.0/fabs(3*((1.0-(10000000.0*(x-1.3))))) + x*x + 1.0;</span>
<span class="token comment">//}</span>

<span class="token function">ubnd_set_str</span><span class="token punctuation">(</span>result<span class="token punctuation">,</span> <span class="token string">"1.0"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">ubnd_mul</span><span class="token punctuation">(</span>temp<span class="token punctuation">,</span> x<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">ubnd_add</span><span class="token punctuation">(</span>result<span class="token punctuation">,</span> temp<span class="token punctuation">,</span> result<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token function">ubnd_sub</span><span class="token punctuation">(</span>temp<span class="token punctuation">,</span> x<span class="token punctuation">,</span> opt<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">ubnd_mul</span><span class="token punctuation">(</span>temp<span class="token punctuation">,</span> bigint<span class="token punctuation">,</span> temp<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">ubnd_sub</span><span class="token punctuation">(</span>temp<span class="token punctuation">,</span> one<span class="token punctuation">,</span> temp<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">ubnd_mul</span><span class="token punctuation">(</span>temp<span class="token punctuation">,</span> three<span class="token punctuation">,</span> temp<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">unum_abs</span><span class="token punctuation">(</span>temp<span class="token punctuation">,</span> temp<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">unum_div</span><span class="token punctuation">(</span>temp<span class="token punctuation">,</span> n_one<span class="token punctuation">,</span> temp<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">ubnd_add</span><span class="token punctuation">(</span>result<span class="token punctuation">,</span> temp<span class="token punctuation">,</span> result<span class="token punctuation">)</span><span class="token punctuation">;</span>




 <span class="token comment">// if (strcmp("add",argv[2]) == 0) { UBND_ROP(fresult,argv[1],add,argv[3]); }</span>
 <span class="token comment">// if (strcmp("sub",argv[2]) == 0) { UBND_ROP(fresult,argv[1],sub,argv[3]); }</span>
 <span class="token comment">// if (strcmp("mul",argv[2]) == 0) { UBND_ROP(fresult,argv[1],mul,argv[3]); }</span>
 <span class="token comment">// if (strcmp("div",argv[2]) == 0) { UBND_ROP(fresult,argv[1],div,argv[3]); }</span>
 
 <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"   Result of "</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">ubnd_print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">" is "</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">ubnd_print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

</pre>
      </div>
      
      
    
    
    
    
    
    
    
    
  </body></html>